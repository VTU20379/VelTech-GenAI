{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPINKpME+eN/4wMPBt50EVc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VTU20379/VelTech-GenAI/blob/main/Bert_mlm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sl4GgEyYncpf"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "from scipy.special import softmax\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bert-base-cased\"\n",
        "\n",
        "# Instantiate the tokenizer and model for the specified pre-trained model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
        "print(tokenizer)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sJjjK9Apycs",
        "outputId": "173ad282-481b-42d1-a6bb-924ef869596f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertTokenizerFast(name_or_path='bert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
            "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n",
            "BertForMaskedLM(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (cls): BertOnlyMLMHead(\n",
            "    (predictions): BertLMPredictionHead(\n",
            "      (transform): BertPredictionHeadTransform(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (transform_act_fn): GELUActivation()\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "      (decoder): Linear(in_features=768, out_features=28996, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the mask token from the tokenizer\n",
        "mask = tokenizer.mask_token\n",
        "print(mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE0oVa9Mp66J",
        "outputId": "87814e5d-2e4b-4d0d-b01a-85379c978f6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MASK]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sentence with a mask token to be filled in by the model\n",
        "sentence = f\"It is good to have {mask} for lunch.\"\n",
        "# Tokenize the sentence\n",
        "tokens = tokenizer.tokenize(sentence)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sANc-s3qqGly",
        "outputId": "febe42fc-3bf0-4425-d41a-644c413edb71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['It', 'is', 'good', 'to', 'have', '[MASK]', 'for', 'lunch', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sentence with a mask token to be filled in by the model\n",
        "sentence = f\"I want to meet {mask} tonight.\"\n",
        "# Tokenize the sentence\n",
        "tokens = tokenizer.tokenize(sentence)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNLn7nPnuAgM",
        "outputId": "d6a6f112-70e4-4934-b1c9-479fa34b984f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'want', 'to', 'meet', '[MASK]', 'tonight', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the sentence using the tokenizer and return the input tensors\n",
        "encoded_inputs = tokenizer(sentence, return_tensors='pt')\n",
        "print(encoded_inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPf7nDA6uU_x",
        "outputId": "78cf48b8-03ca-4ffe-9b69-94ce622a6d4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 101,  146, 1328, 1106, 2283,  103, 3568,  119,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#encoded_inputs=tokenizer(sentence)\n",
        "#print(encoded_inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd0BNtunu4Os",
        "outputId": "74f5169b-01a8-4f69-faaf-3ec44642491a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 146, 1328, 1106, 2283, 103, 3568, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**encoded_inputs)\n",
        "outputs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGxwOgWIvSHi",
        "outputId": "e8118b6a-76c2-4d9d-d703-f1659511bec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MaskedLMOutput(loss=None, logits=tensor([[[ -7.2080,  -7.1081,  -7.2716,  ...,  -6.0417,  -5.8467,  -6.1377],\n",
              "         [ -7.9152,  -8.2049,  -7.9754,  ...,  -6.6298,  -6.4941,  -6.8368],\n",
              "         [-12.4463, -12.3040, -12.1644,  ...,  -6.9075,  -7.5696,  -7.8245],\n",
              "         ...,\n",
              "         [ -7.7738,  -8.0661,  -7.0037,  ...,  -5.7493,  -5.9397,  -7.0409],\n",
              "         [-11.7280, -11.7840, -11.6647,  ...,  -8.4709,  -9.0766,  -9.8484],\n",
              "         [-13.4606, -14.2306, -13.9173,  ...,  -9.6105, -11.8186, -10.8183]]],\n",
              "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits=outputs.logits.detach().numpy()[0]\n",
        "logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-pQcTNOwGst",
        "outputId": "b187b301-a602-4cef-9ce3-48db0cb1146e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 28996)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0xmaH0nwiUw",
        "outputId": "43dc9b26-2d37-41de-96a8-2d19082973e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask_logits=logits[tokens.index(mask)+1]\n",
        "mask_logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsvOTWctxNyo",
        "outputId": "9d5cd1ef-2349-4f5c-8dcd-862c98899a1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-5.632214 , -5.705392 , -5.5025053, ..., -5.3011913, -5.295761 ,\n",
              "       -5.3564987], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confidence=softmax(mask_logits)\n",
        "confidence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDTXKVbuxwg9",
        "outputId": "e52507b1-59a0-40cf-97aa-af3c7bebd5d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.0081819e-08, 9.3704058e-09, 1.1478123e-08, ..., 1.4037833e-08,\n",
              "       1.4114296e-08, 1.3282541e-08], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confidence.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EdQyQ_Cx9KX",
        "outputId": "7d31b65f-79d2-4376-e06e-75d2afa86049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999999"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in np.argsort(confidence_scores)[::-1][:5]:\n",
        "    pred_token = tokenizer.decode(i)\n",
        "    score = confidence_scores[i]\n",
        "\n",
        "    # Print the predicted sentence with the mask token replaced by the predicted token, and the confidence score\n",
        "    print(sentence.replace(mask, pred_token), score)"
      ],
      "metadata": {
        "id": "-GSgEPF1yP2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in np.argsort(confidence)[::-1][:5]:\n",
        "  pred=tokenizer.decode(i)\n",
        "  score=confidence[i]\n",
        "  print(sentence.replace(mask,pred),score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHrYsHG1yRvX",
        "outputId": "f188b0a2-658b-40e3-e469-fb16d79dc205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I want to meet you tonight. 0.3609081\n",
            "I want to meet him tonight. 0.18192914\n",
            "I want to meet her tonight. 0.14262769\n",
            "I want to meet someone tonight. 0.03402644\n",
            "I want to meet again tonight. 0.022109564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in np.argsort(confidence)[::-1][:5]:\n",
        "  pred=tokenizer.decode(i)\n",
        "  score=confidence[i]\n",
        "  print(sentence.replace(mask,pred),score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKOjdtzt1vig",
        "outputId": "c6143e49-7fa5-414a-ca6a-f3c3ef3e89e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I want to meet you tonight. 0.3609081\n",
            "I want to meet him tonight. 0.18192914\n",
            "I want to meet her tonight. 0.14262769\n",
            "I want to meet someone tonight. 0.03402644\n",
            "I want to meet again tonight. 0.022109564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MryBtyuA2AFq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}